{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 - MedGemma Integration (Kaggle)\n",
    "\n",
    "Notebook para gerar relatorio clinico estruturado a partir dos outputs dos 3 modelos:\n",
    "- Glaucoma (TransUNet)\n",
    "- DR Grading (EfficientNet)\n",
    "- Vascular (U-Net)\n",
    "\n",
    "Com fallback rule-based se o MedGemma nao estiver disponivel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install transformers accelerate sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, Dict\n",
    "\n",
    "@dataclass\n",
    "class ScreeningResults:\n",
    "    cdr: float\n",
    "    glaucoma_risk: str\n",
    "    dr_grade: int\n",
    "    dr_label: str\n",
    "    dr_conf: float\n",
    "    vessel_density: float\n",
    "\n",
    "def build_prompt(r: ScreeningResults) -> str:\n",
    "    return f\"\"\"You are a clinical ophthalmology AI assistant. Based on the following automated retinal screening results, generate a structured clinical report.\n",
    "\n",
    "PATIENT SCREENING RESULTS:\n",
    "- Glaucoma Assessment: CDR = {r.cdr:.3f} | Risk: {r.glaucoma_risk}\n",
    "- Diabetic Retinopathy: Grade {r.dr_grade} ({r.dr_label}) | Confidence: {r.dr_conf:.1%}\n",
    "- Vascular Analysis: Vessel density = {r.vessel_density:.1%} | Segmentation available\n",
    "\n",
    "Generate a report with:\n",
    "1. FINDINGS\n",
    "2. RISK ASSESSMENT (low/moderate/high/emergent)\n",
    "3. RECOMMENDATIONS (follow-up interval, referrals, exams)\n",
    "4. DISCLAIMER (AI-assisted screening, not diagnosis)\n",
    "\"\"\"\n",
    "\n",
    "def overall_risk(r: ScreeningResults) -> str:\n",
    "    if r.dr_grade >= 4 or r.cdr >= 0.75:\n",
    "        return \"emergent\"\n",
    "    if r.dr_grade >= 3 or r.cdr >= 0.65:\n",
    "        return \"high\"\n",
    "    if r.dr_grade >= 2 or r.cdr >= 0.55:\n",
    "        return \"moderate\"\n",
    "    return \"low\"\n",
    "\n",
    "def rule_based_report(r: ScreeningResults) -> str:\n",
    "    risk = overall_risk(r)\n",
    "    follow = {\n",
    "        \"emergent\": \"Urgent ophthalmology referral within 24-72 hours.\",\n",
    "        \"high\": \"Specialist assessment within 1-2 weeks.\",\n",
    "        \"moderate\": \"Follow-up in 1-3 months with repeat retinal imaging.\",\n",
    "        \"low\": \"Routine annual screening and risk-factor control.\",\n",
    "    }[risk]\n",
    "\n",
    "    return (\n",
    "        \"1. FINDINGS\\n\"\n",
    "        f\"- Glaucoma screening: CDR {r.cdr:.3f}, risk category {r.glaucoma_risk}.\\n\"\n",
    "        f\"- DR grading: Grade {r.dr_grade} ({r.dr_label}), confidence {r.dr_conf:.1%}.\\n\"\n",
    "        f\"- Vascular analysis: estimated vessel density {r.vessel_density:.1%}.\\n\\n\"\n",
    "        \"2. RISK ASSESSMENT\\n\"\n",
    "        f\"- Overall triage risk: {risk}.\\n\\n\"\n",
    "        \"3. RECOMMENDATIONS\\n\"\n",
    "        f\"- {follow}\\n\"\n",
    "        \"- Correlate with clinical exam, IOP, OCT, and visual acuity.\\n\\n\"\n",
    "        \"4. DISCLAIMER\\n\"\n",
    "        \"- This is AI-assisted retinal screening support and not a definitive diagnosis.\"\n",
    "    )\n",
    "\n",
    "def medgemma_generate(prompt: str, model_id: str = \"google/medgemma-4b-it\", max_new_tokens: int = 420) -> Tuple[Optional[str], Optional[str]]:\n",
    "    try:\n",
    "        import torch\n",
    "        from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_id,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            device_map=\"auto\",\n",
    "        )\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_new_tokens,\n",
    "                temperature=0.2,\n",
    "                do_sample=True,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "            )\n",
    "        text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        if text.startswith(prompt):\n",
    "            text = text[len(prompt):].strip()\n",
    "        return text, None\n",
    "    except Exception as e:\n",
    "        return None, str(e)\n",
    "\n",
    "def generate_report(r: ScreeningResults, use_medgemma: bool = True) -> Dict[str, str]:\n",
    "    prompt = build_prompt(r)\n",
    "    fallback = rule_based_report(r)\n",
    "    if not use_medgemma:\n",
    "        return {\"mode\": \"rule_based_only\", \"report\": fallback, \"prompt\": prompt, \"error\": \"\"}\n",
    "    out, err = medgemma_generate(prompt)\n",
    "    if out is None:\n",
    "        return {\"mode\": \"fallback_rule_based\", \"report\": fallback, \"prompt\": prompt, \"error\": err or \"unknown\"}\n",
    "    return {\"mode\": \"medgemma\", \"report\": out, \"prompt\": prompt, \"error\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitua pelos valores reais inferidos dos seus 3 modelos\n",
    "results = ScreeningResults(\n",
    "    cdr=0.612,\n",
    "    glaucoma_risk=\"high\",\n",
    "    dr_grade=2,\n",
    "    dr_label=\"Moderate\",\n",
    "    dr_conf=0.9616,\n",
    "    vessel_density=0.12,\n",
    ")\n",
    "\n",
    "output = generate_report(results, use_medgemma=True)\n",
    "print(\"MODE:\", output[\"mode\"])\n",
    "if output[\"error\"]:\n",
    "    print(\"ERROR:\", output[\"error\"])\n",
    "print(\"\\nREPORT:\\n\")\n",
    "print(output[\"report\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opcional: salvar relatorio em arquivo\n",
    "import os, json\n",
    "\n",
    "os.makedirs(\"/kaggle/working/outputs/medgemma\", exist_ok=True)\n",
    "with open(\"/kaggle/working/outputs/medgemma/clinical_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(output[\"report\"])\n",
    "\n",
    "with open(\"/kaggle/working/outputs/medgemma/clinical_report_meta.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\n",
    "        \"mode\": output[\"mode\"],\n",
    "        \"error\": output[\"error\"],\n",
    "        \"inputs\": results.__dict__,\n",
    "    }, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\"- /kaggle/working/outputs/medgemma/clinical_report.txt\")\n",
    "print(\"- /kaggle/working/outputs/medgemma/clinical_report_meta.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integracao no app/demo\n",
    "\n",
    "Use os outputs reais dos modelos treinados:\n",
    "- `cdr` e `glaucoma_risk` do TransUNet\n",
    "- `dr_grade` e `dr_conf` do EfficientNet\n",
    "- `vessel_density` da segmentacao vascular\n",
    "\n",
    "Se o MedGemma nao carregar no Kaggle, o fallback rule-based garante relatorio estavel para a demo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
